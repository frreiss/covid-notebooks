{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attended-grenada",
   "metadata": {
    "papermill": {
     "duration": 0.026916,
     "end_time": "2021-03-26T21:23:53.608709",
     "exception": false,
     "start_time": "2021-03-26T21:23:53.581793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# fit_us_data-digest.ipynb\n",
    "\n",
    "Key parts of the notebook `fit_us_data.ipynb` broken out for the purpose of demonstrating the use of Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-crash",
   "metadata": {
    "papermill": {
     "duration": 1.081613,
     "end_time": "2021-03-26T21:23:54.711795",
     "exception": false,
     "start_time": "2021-03-26T21:23:53.630182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialization boilerplate\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "from sklearn import metrics\n",
    "import time\n",
    "#from typing import List\n",
    "\n",
    "import ipywidgets\n",
    "import IPython.display\n",
    "\n",
    "import text_extensions_for_pandas as tp\n",
    "\n",
    "# Local file of utility functions\n",
    "import util\n",
    "\n",
    "# What precision of floating-point to use.\n",
    "# Consider 32-bit if using GPU-accelerated solvers. Otherwise, 64-bit\n",
    "# floating point is better because it reduces the chance of divergence.\n",
    "fp_type = np.float64\n",
    "\n",
    "# Allow environment variables to override data file locations.\n",
    "_OUTPUTS_DIR = os.getenv(\"COVID_OUTPUTS_DIR\", \"outputs\")\n",
    "util.ensure_dir_exists(_OUTPUTS_DIR)  # create if necessary\n",
    "\n",
    "\n",
    "_NUM_COUNTIES = 3081\n",
    "\n",
    "\n",
    "# Code for displaying progress bars\n",
    "def make_progress_bar():\n",
    "    progress_bar = ipywidgets.IntProgress(\n",
    "        0, 0, _NUM_COUNTIES, description=\"Fitting curves...\",\n",
    "        layout=ipywidgets.Layout(width=\"100%\"),\n",
    "        style={\"description_width\": \"15%\"})\n",
    "    IPython.display.display(progress_bar)\n",
    "    return progress_bar\n",
    "\n",
    "\n",
    "def update_progress_bar(progress_bar: ipywidgets.IntProgress, num_done: int):\n",
    "    progress_bar.value = num_done\n",
    "    progress_bar.description = f\"{num_done} of {_NUM_COUNTIES} counties\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-comment",
   "metadata": {
    "papermill": {
     "duration": 0.015901,
     "end_time": "2021-03-26T21:23:54.743684",
     "exception": false,
     "start_time": "2021-03-26T21:23:54.727783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-function",
   "metadata": {
    "papermill": {
     "duration": 0.115411,
     "end_time": "2021-03-26T21:23:54.878919",
     "exception": false,
     "start_time": "2021-03-26T21:23:54.763508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# Load data.\n",
    "dates_file = os.path.join(_OUTPUTS_DIR, \"dates.feather\")\n",
    "cases_file = os.path.join(_OUTPUTS_DIR, \"us_counties_clean.feather\")\n",
    "cases = pd.read_feather(cases_file).set_index(\"FIPS\")\n",
    "dates = pd.read_feather(dates_file)[\"date\"].to_numpy()\n",
    "\n",
    "####################################################################################\n",
    "# Drop time series that are subject to aliasing.\n",
    "alias_threshold = 100\n",
    "ts_col_name = \"Confirmed\"\n",
    "\n",
    "# We also cut off the sections at the beginning of the time \n",
    "# series where every time series' value is below this threshold.\n",
    "\n",
    "# Find what point in the time series at least one county went above\n",
    "# the threshold.\n",
    "first_time_above_min = np.argmax(np.max(cases[ts_col_name].array, axis=0) >= alias_threshold)\n",
    "print(f\"Dropping the first {first_time_above_min} elements of each time series.\")\n",
    "\n",
    "# Find which counties have at least one time series value above the \n",
    "# threshold.\n",
    "counties_mask = np.max(cases[ts_col_name].array, axis=1) >= alias_threshold\n",
    "\n",
    "# Filter rows\n",
    "filtered = cases[counties_mask].copy(deep=True)\n",
    "\n",
    "# Truncate time series to just the times when at least one county\n",
    "# was above our threshold.\n",
    "filtered[ts_col_name] = filtered[ts_col_name].array[:,first_time_above_min:]\n",
    "\n",
    "# Also filter the outlier masks\n",
    "outlier_col_name = ts_col_name + \"_Outlier\"\n",
    "filtered[outlier_col_name] = filtered[outlier_col_name].array[:,first_time_above_min:]\n",
    "\n",
    "filtered_dates = dates[first_time_above_min:]\n",
    "\n",
    "# Drop time series columns other than the one we analyze\n",
    "series_to_keep = [ts_col_name, outlier_col_name]\n",
    "metadata_cols = []\n",
    "to_drop = []\n",
    "for colname in filtered.columns:\n",
    "    if not isinstance(filtered[colname].dtype, tp.TensorDtype):\n",
    "        metadata_cols.append(colname)\n",
    "    elif colname not in series_to_keep:\n",
    "        to_drop.append(colname)\n",
    "\n",
    "filtered = filtered.drop(columns=to_drop)\n",
    "\n",
    "# Figure out how many values remain\n",
    "series_len = filtered.iloc[0][\"Confirmed\"].to_numpy().shape[0]\n",
    "\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-cooking",
   "metadata": {},
   "source": [
    "# Define the parameters of the curve-fitting operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_fn(x, var_values):\n",
    "    max_, rate, offset = var_values\n",
    "    # Y = max / (1 + e^(-rate *(X - offset))\n",
    "    return max_ / (1.0 + np.exp(-rate * (x - offset)))\n",
    "\n",
    "\n",
    "x_values = np.linspace(0, series_len - 1, series_len, dtype=fp_type)\n",
    "def logistic_objective(var_values, y):\n",
    "    return np.sum((y - (logistic_fn(x_values, var_values))) ** 2)\n",
    "\n",
    "param_names = (\"Max\", \"Rate\", \"Offset\")\n",
    "initial_guess = (1000.0, 0.1, 1.0)\n",
    "logistic_bounds = ((0.0, 1e6), (0.0, 1.0), (0.0, float(len(filtered_dates))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-algeria",
   "metadata": {},
   "source": [
    "# Fit the logistic function to 3081 time series, *without* Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic(points: np.array):\n",
    "    return scipy.optimize.minimize(\n",
    "        logistic_objective, initial_guess,\n",
    "        args=(points), bounds=logistic_bounds)\n",
    "\n",
    "\n",
    "progress_bar = make_progress_bar()\n",
    "start_time = time.time()\n",
    "\n",
    "results = []\n",
    "for time_series in filtered[\"Confirmed\"]:\n",
    "    results.append(fit_logistic(time_series.to_numpy()))\n",
    "    update_progress_bar(progress_bar, len(results))\n",
    "\n",
    "print(f\"Fit {len(results)} time series in {time.time() - start_time:0.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-matter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-frontier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-kruger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-northeast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-january",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "regulated-current",
   "metadata": {},
   "source": [
    "# Fit the logistic function to 3081 time series, *with* RayÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.init(num_cpus=32, resources={\"ram\": 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=4, resources={\"ram\": 8})\n",
    "def fit_logistic(points: np.array):\n",
    "    return scipy.optimize.minimize(\n",
    "        logistic_objective, initial_guess,\n",
    "        args=(points), bounds=logistic_bounds)\n",
    "\n",
    "progress_bar = make_progress_bar()\n",
    "start_time = time.time()\n",
    "\n",
    "results = []\n",
    "futures = []\n",
    "for time_series in filtered[\"Confirmed\"]:\n",
    "    futures.append(fit_logistic.remote(time_series.to_numpy()))\n",
    "    \n",
    "while len(results) < _NUM_COUNTIES:\n",
    "    results.append(ray.wait(futures, num_returns=1, timeout=None))\n",
    "    update_progress_bar(progress_bar, len(results))\n",
    "\n",
    "print(f\"Fit {len(results)} time series in {time.time() - start_time:0.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-worse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-trigger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-transmission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-strengthening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-cambodia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-holmes",
   "metadata": {
    "papermill": {
     "duration": 0.05416,
     "end_time": "2021-03-26T21:25:44.622121",
     "exception": false,
     "start_time": "2021-03-26T21:25:44.567961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "duration": 114.641043,
   "end_time": "2021-03-26T21:25:47.293194",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/freiss/pd/fred-covid-notebooks/cn-ray2/notebooks/fit_us_data.ipynb",
   "output_path": "/Users/freiss/pd/fred-covid-notebooks/cn-ray2/notebooks/fit_us_data.ipynb",
   "parameters": {},
   "start_time": "2021-03-26T21:23:52.652151",
   "version": "2.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
